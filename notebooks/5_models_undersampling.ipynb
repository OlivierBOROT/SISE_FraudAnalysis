{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5341d8a1",
   "metadata": {},
   "source": [
    "# Using undersampling to reequilibrate the classes, and the reiterate a selection of stacking model on the rebalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ace15",
   "metadata": {},
   "source": [
    "**Strategy:**\n",
    "- For each validation set / For each model:\n",
    "    - Undersample the majority category (down to 10 % ?)\n",
    "    - SMOTE the minority class (up to 25%)\n",
    "    - Train select the best hyperparameters for various models\n",
    "    - Stack the models\n",
    "    - Apply on the full test dataset\n",
    "\n",
    "**To be tried**\n",
    "- Tomek link (When classes overlap)\n",
    "- NearMiss (When decision boundary matters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec8d2d",
   "metadata": {},
   "source": [
    "## Library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588f4458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\axel-\\Documents\\Coding\\SISE_FraudAnalysis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\axel-\\\\Documents\\\\Coding\\\\SISE_FraudAnalysis'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path managememnt\n",
    "import os\n",
    "\n",
    "# print path\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "# change path\n",
    "os.chdir(\"C:/Users/axel-/Documents/Coding/SISE_FraudAnalysis\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a50a8781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "import pickle\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "import mlflow\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44bc8f",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671ddadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cleaned_data.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ca9f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ZIBZIN",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "IDAvisAutorisationCheque",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "FlagImpaye",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Montant",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DateTransaction",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "CodeDecision",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "VerifianceCPT1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "VerifianceCPT2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "VerifianceCPT3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "D2CB",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ScoringFP1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ScoringFP2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ScoringFP3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TauxImpNb_RB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TauxImpNB_CPM",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "EcartNumCheq",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "NbrMagasin3J",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DiffDateTr1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DiffDateTr2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DiffDateTr3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CA3TRetMtt",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CA3TR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Heure",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "JourSemaine",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "6d41d57a-e5c9-412f-a616-3edcc4c0f87d",
       "rows": [
        [
         "0",
         "A013010004908126703060931",
         "78643044",
         "0",
         "20.0",
         "2017-02-01 07:32:14",
         "1",
         "0",
         "0",
         "0",
         "551",
         "0.0",
         "0.0",
         "0.0",
         "37.18666789091911",
         "52.07603375736141",
         "0",
         "1",
         "4.0",
         "4.0",
         "4.0",
         "20.0",
         "0.0",
         "27134",
         "2"
        ],
        [
         "1",
         "A013011306908024927155000",
         "78643045",
         "0",
         "20.0",
         "2017-02-01 07:43:37",
         "1",
         "0",
         "0",
         "0",
         "551",
         "0.0",
         "0.0",
         "0.0",
         "48.84471627590894",
         "52.07603375736141",
         "1",
         "2",
         "1.7976851851851852",
         "4.0",
         "4.0",
         "28.61",
         "8.61",
         "27817",
         "2"
        ],
        [
         "2",
         "A013010002908283134592527",
         "78643046",
         "0",
         "57.64",
         "2017-02-01 07:47:38",
         "1",
         "0",
         "0",
         "0",
         "549",
         "0.0",
         "0.0",
         "0.0",
         "73.11827956989248",
         "52.07603375736141",
         "0",
         "1",
         "4.0",
         "4.0",
         "4.0",
         "57.64",
         "0.0",
         "28058",
         "2"
        ],
        [
         "3",
         "A011010002908105209831316",
         "78643047",
         "0",
         "54.29",
         "2017-02-01 07:48:48",
         "0",
         "1",
         "1",
         "1",
         "267",
         "0.0",
         "0.0",
         "0.0",
         "110.05692599620494",
         "53.554233554497365",
         "0",
         "1",
         "4.0",
         "4.0",
         "4.0",
         "54.29",
         "0.0",
         "28128",
         "2"
        ],
        [
         "4",
         "A013010041908000125652029",
         "78643048",
         "0",
         "26.9",
         "2017-02-01 08:13:27",
         "1",
         "0",
         "0",
         "0",
         "549",
         "0.003769090654336556",
         "8.586333428666261",
         "0.0011922637097134124",
         "45.36831264567185",
         "52.07603375736141",
         "1",
         "1",
         "1.9971064814814814",
         "4.0",
         "4.0",
         "59.15",
         "32.25",
         "29607",
         "2"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIBZIN</th>\n",
       "      <th>IDAvisAutorisationCheque</th>\n",
       "      <th>FlagImpaye</th>\n",
       "      <th>Montant</th>\n",
       "      <th>DateTransaction</th>\n",
       "      <th>CodeDecision</th>\n",
       "      <th>VerifianceCPT1</th>\n",
       "      <th>VerifianceCPT2</th>\n",
       "      <th>VerifianceCPT3</th>\n",
       "      <th>D2CB</th>\n",
       "      <th>...</th>\n",
       "      <th>TauxImpNB_CPM</th>\n",
       "      <th>EcartNumCheq</th>\n",
       "      <th>NbrMagasin3J</th>\n",
       "      <th>DiffDateTr1</th>\n",
       "      <th>DiffDateTr2</th>\n",
       "      <th>DiffDateTr3</th>\n",
       "      <th>CA3TRetMtt</th>\n",
       "      <th>CA3TR</th>\n",
       "      <th>Heure</th>\n",
       "      <th>JourSemaine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A013010004908126703060931</td>\n",
       "      <td>78643044</td>\n",
       "      <td>0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2017-02-01 07:32:14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>551</td>\n",
       "      <td>...</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27134</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A013011306908024927155000</td>\n",
       "      <td>78643045</td>\n",
       "      <td>0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2017-02-01 07:43:37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>551</td>\n",
       "      <td>...</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.797685</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.61</td>\n",
       "      <td>8.61</td>\n",
       "      <td>27817</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A013010002908283134592527</td>\n",
       "      <td>78643046</td>\n",
       "      <td>0</td>\n",
       "      <td>57.64</td>\n",
       "      <td>2017-02-01 07:47:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>549</td>\n",
       "      <td>...</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>57.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28058</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A011010002908105209831316</td>\n",
       "      <td>78643047</td>\n",
       "      <td>0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>2017-02-01 07:48:48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>...</td>\n",
       "      <td>53.554234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A013010041908000125652029</td>\n",
       "      <td>78643048</td>\n",
       "      <td>0</td>\n",
       "      <td>26.90</td>\n",
       "      <td>2017-02-01 08:13:27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>549</td>\n",
       "      <td>...</td>\n",
       "      <td>52.076034</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.997106</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>59.15</td>\n",
       "      <td>32.25</td>\n",
       "      <td>29607</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ZIBZIN IDAvisAutorisationCheque  FlagImpaye  Montant  \\\n",
       "0  A013010004908126703060931                 78643044           0    20.00   \n",
       "1  A013011306908024927155000                 78643045           0    20.00   \n",
       "2  A013010002908283134592527                 78643046           0    57.64   \n",
       "3  A011010002908105209831316                 78643047           0    54.29   \n",
       "4  A013010041908000125652029                 78643048           0    26.90   \n",
       "\n",
       "      DateTransaction  CodeDecision  VerifianceCPT1  VerifianceCPT2  \\\n",
       "0 2017-02-01 07:32:14             1               0               0   \n",
       "1 2017-02-01 07:43:37             1               0               0   \n",
       "2 2017-02-01 07:47:38             1               0               0   \n",
       "3 2017-02-01 07:48:48             0               1               1   \n",
       "4 2017-02-01 08:13:27             1               0               0   \n",
       "\n",
       "   VerifianceCPT3  D2CB  ...  TauxImpNB_CPM  EcartNumCheq  NbrMagasin3J  \\\n",
       "0               0   551  ...      52.076034             0             1   \n",
       "1               0   551  ...      52.076034             1             2   \n",
       "2               0   549  ...      52.076034             0             1   \n",
       "3               1   267  ...      53.554234             0             1   \n",
       "4               0   549  ...      52.076034             1             1   \n",
       "\n",
       "   DiffDateTr1  DiffDateTr2 DiffDateTr3  CA3TRetMtt  CA3TR  Heure  JourSemaine  \n",
       "0     4.000000          4.0         4.0       20.00   0.00  27134            2  \n",
       "1     1.797685          4.0         4.0       28.61   8.61  27817            2  \n",
       "2     4.000000          4.0         4.0       57.64   0.00  28058            2  \n",
       "3     4.000000          4.0         4.0       54.29   0.00  28128            2  \n",
       "4     1.997106          4.0         4.0       59.15  32.25  29607            2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "811b2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing type of EcartNumCheq column\n",
    "df[\"EcartNumCheq\"] = df[\"EcartNumCheq\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369e74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = (df['DateTransaction'] >= '2017-02-01') & (df['DateTransaction'] <= '2017-08-31')\n",
    "test_index = (df['DateTransaction'] >= '2017-09-01') & (df['DateTransaction'] <= '2017-11-30')\n",
    "\n",
    "train = df[train_index]\n",
    "test = df[test_index]\n",
    "    \n",
    "del train_index, test_index\n",
    "\n",
    "# Variable to discard\n",
    "to_discard = ['ZIBZIN', 'IDAvisAutorisationCheque', 'DateTransaction','CodeDecision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d0421ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=to_discard)\n",
    "train = train.drop(columns=to_discard)\n",
    "\n",
    "y_train = train['FlagImpaye']\n",
    "X_train = train.drop(columns=['FlagImpaye'])\n",
    "y_test = test['FlagImpaye']\n",
    "X_test = test.drop(columns=['FlagImpaye'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e47c288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scorer on positive class (fraud cases)\n",
    "f1_fraud_scorer = make_scorer(\n",
    "    f1_score,\n",
    "    pos_label=1,  # Focus sur les fraudes\n",
    "    average='binary'  # Binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aecf210",
   "metadata": {},
   "source": [
    "## Random Undersampling  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2930a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [3865122   23346]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf1002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ratio = 0.20\n",
    "# define strategy for undersampling\n",
    "sampling = {\n",
    "    0: counts[1],  \n",
    "    1: counts[1]     \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bcb4763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersample train set down to 10 % of the minority class\n",
    "rus = RandomUnderSampler(sampling_strategy = 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fabfd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9853ce42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "FlagImpaye",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "proportion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1364cd6d-2477-4c85-8bfe-04aa1b0e299d",
       "rows": [
        [
         "0",
         "0.9090909090909091"
        ],
        [
         "1",
         "0.09090909090909091"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "FlagImpaye\n",
       "0    0.909091\n",
       "1    0.090909\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e54c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply SMOTE to resampled data to reach at least 20% of minority class\n",
    "smote = SMOTE(sampling_strategy=0.25)\n",
    "X_final, y_final = smote.fit_resample(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "034d51b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "FlagImpaye",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "proportion",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "4464b626-4e5e-45e5-b29e-765c3df6d3f1",
       "rows": [
        [
         "0",
         "0.8"
        ],
        [
         "1",
         "0.2"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "FlagImpaye\n",
       "0    0.8\n",
       "1    0.2\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_final.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "304cc86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples after undersampling and SMOTE:\n",
      "FlagImpaye\n",
      "0    233460\n",
      "1     58365\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples after undersampling and SMOTE:\")\n",
    "print(y_final.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7077e0",
   "metadata": {},
   "source": [
    "# Pipeline configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aeb5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Define the percentage of minority class after resampling\n",
    "target_undersampler = 0.10\n",
    "target_smote = 0.25\n",
    "\n",
    "\n",
    "# define models and their hyperparameters (keep the same sampling strategy in the pipeline)\n",
    "models_params = {\n",
    "    'RandomForest': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('rus', RandomUnderSampler(sampling_strategy=target_undersampler, )),\n",
    "            ('smote', SMOTE(sampling_strategy=target_smote, )),\n",
    "            ('model', RandomForestClassifier(n_jobs=-1))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__n_estimators': [200, 300, 500],\n",
    "            'model__max_depth': [15, 20],\n",
    "            'model__min_samples_split': [5, 10],\n",
    "            'model__class_weight': [{0: 1, 1: 10}, {0:1, 1:20},  {0:1, 1:15} , 'balanced']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'LightGBM': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('rus', RandomUnderSampler(sampling_strategy=target_undersampler, )),\n",
    "            ('smote', SMOTE(sampling_strategy=target_smote, )),\n",
    "            ('model', LGBMClassifier(n_jobs=-1, verbose=-1))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__n_estimators': [300, 400],\n",
    "            'model__max_depth': [7, 10],\n",
    "            'model__learning_rate': [0.05, 0.1],\n",
    "            'model__num_leaves': [31, 50],\n",
    "            'model__class_weight': [{0: 1, 1: 10}, {0:1, 1:20},  {0:1, 1:15} , 'balanced']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'XGBoost': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('rus', RandomUnderSampler(sampling_strategy=target_undersampler, )),\n",
    "            ('smote', SMOTE(sampling_strategy=target_smote, )),\n",
    "            ('model', HistGradientBoostingClassifier(max_iter=300))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__n_estimators': [200, 300],\n",
    "            'model__max_depth': [5, 7],\n",
    "            'model__learning_rate': [0.05, 0.1],\n",
    "            'model__scale_pos_weight': [3, 4],\n",
    "            'model__subsample': [0.8, 0.9],\n",
    "            'model__class_weight': [{0: 1, 1: 10}, {0:1, 1:20},  {0:1, 1:15} , 'balanced']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # LogisticRegression\n",
    "    'logistic_regression': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('rus', RandomUnderSampler(sampling_strategy=target_undersampler, )),\n",
    "            ('smote', SMOTE(sampling_strategy=target_smote, )),\n",
    "            ('model', LogisticRegression(max_iter=1000, n_jobs=-1))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__C': [0.01, 0.1, 1.0, 10.0],\n",
    "            'model__penalty': ['l2'],\n",
    "            'model__class_weight': [{0: 1, 1: 10}, {0:1, 1:20},  {0:1, 1:15} , 'balanced']\n",
    "        }\n",
    "    },\n",
    "\n",
    "        # Neural network\n",
    "    'neural_network': {\n",
    "        'pipeline': Pipeline([\n",
    "            ('rus', RandomUnderSampler(sampling_strategy=target_undersampler, )),\n",
    "            ('smote', SMOTE(sampling_strategy=target_smote, )),\n",
    "            ('model', MLPClassifier(max_iter=500))\n",
    "        ]),\n",
    "        'params': {\n",
    "            'model__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'model__activation': ['relu', 'tanh'],\n",
    "            'model__alpha': [0.0001, 0.001, 0.01],\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ebf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/13 21:50:24 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2026/01/13 21:50:24 INFO mlflow.store.db.utils: Updating database tables\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
      "2026/01/13 21:50:24 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
      "2026/01/13 21:50:25 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
      "2026/01/13 21:50:25 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
      "2026/01/13 21:50:25 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
      "2026/01/13 21:50:25 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
      "2026/01/13 21:50:25 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
      "2026/01/13 21:50:25 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
      "2026/01/13 21:50:25 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
      "2026/01/13 21:50:25 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
      "2026/01/13 21:50:25 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
      "2026/01/13 21:50:25 INFO mlflow.tracking.fluent: Experiment with name 'sampling_models_experiments' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV for RandomForest...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m mlflow.log_params(grid_search.best_params_)\n\u001b[32m     28\u001b[39m mlflow.log_metric(\u001b[33m\"\u001b[39m\u001b[33mbest_f1_score\u001b[39m\u001b[33m\"\u001b[39m, grid_search.best_score_)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m mlflow.log_metric(\u001b[33m\"\u001b[39m\u001b[33mtraining_time_seconds\u001b[39m\u001b[33m\"\u001b[39m, (\u001b[43mend_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrat_time\u001b[49m) / \u001b[32m1000\u001b[39m)\n\u001b[32m     30\u001b[39m mlflow.sklearn.log_model(grid_search.best_estimator_, artifact_path=\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCompleted GridSearchCV for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Best F1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search.best_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for -: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "# Set up the gridsearch with cross validation and mlflow\n",
    "\n",
    "mlflow.set_experiment(\"sampling_models_experiments\")\n",
    "\n",
    "for model_name, mp in models_params.items():\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        print(f\"Starting GridSearchCV for {model_name}...\")\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=mp['pipeline'],\n",
    "            param_grid=mp['params'],\n",
    "            scoring=f1_fraud_scorer,\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Fit the grid search\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # log the best parameters and the best score\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metric(\"best_f1_score\", grid_search.best_score_)\n",
    "        mlflow.sklearn.log_model(grid_search.best_estimator_, artifact_path=\"model\")\n",
    "        mlflow.log_metric(\"training_time_seconds\", end_time - start_time)\n",
    "        \n",
    "        \n",
    "        print(f\"Completed GridSearchCV for {model_name}. Best F1 Score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899684b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376226f",
   "metadata": {},
   "source": [
    "Exemple of pipeline\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import numpy as np\n",
    "\n",
    "# Base model 1: full dataset\n",
    "model_full = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Base model 2: undersampled\n",
    "model_under = Pipeline([\n",
    "    ('rus', RandomUnderSampler(random_state=42)),\n",
    "    ('clf', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# Get OOF predictions\n",
    "oof_full = cross_val_predict(model_full, X_train, y_train, cv=5, method='predict_proba')[:,1]\n",
    "oof_under = cross_val_predict(model_under, X_train, y_train, cv=5, method='predict_proba')[:,1]\n",
    "\n",
    "# Stack predictions as features for meta-model\n",
    "X_meta = np.column_stack([oof_full, oof_under])\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(X_meta, y_train)\n",
    "\n",
    "# Test predictions\n",
    "pred_full_test = model_full.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "pred_under_test = model_under.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "X_meta_test = np.column_stack([pred_full_test, pred_under_test])\n",
    "final_pred = meta_model.predict(X_meta_test)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sise-fraudanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
